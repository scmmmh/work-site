Quality Assurance and the Death of Good Teaching
################################################

:date: 2016-12-07 18:00
:modified: 2017-11-01 10:08
:tags: quality assurance, teaching, tef
:category: Teaching
:authors: Mark Hall
:summary: How Quality Assurance in UK Universities actively drives down teaching quality.

This is a post based on a talk I gave at Edge Hill University’s Centre for Learning and Teaching Conference, which was originally titled “Student-centred Learning, Quality Assurance, and the Death of Good Teaching”. After preparing and giving the talk, I have decided to chop the first bit off, as it distracted from the main message.

I will write about this in more detail at some point, but fundamentally the context is that student-centred learning and its resulting focus on student satisfaction has a direct, negative impact on teaching quality, as academic staff are essentially rewarded for lowering the quality of their teaching and assessment. This keeps students happy, as they have to do less work, and increases pass rates, another frequently used metric. In order to counter these pressures on academic quality, a large amount of quality-assurance processes have been created. The point I will make in this post is that rather than ensuring quality, in practice not only do they fail to do that, they actively inhibit good teaching. This is, admittedly, based on anecdotal evidence, but the problem is that the anecdotes highlight serious failings, which simply should not pass any Quality Assurance (QA) process, rather than minor failings which can slip through.

QA in University teaching generally happens at three levels. QA of curricula as a whole, QA of individual module structures, and QA of individual module content. The aim of the first two is to validate that the structure and planned content of a curriculum or module is appropriate to current thinking in the discipline, is at an appropriate level, and that it can successfully be delivered by the teaching staff. This is generally implemented via a set of validation committees and panels. The third validation level is there to ensure that what is taught and assessed is of an appropriate level and in line with the structure that was validated. The theory is that after having run through all three levels the teaching will be appropriate and of high quality.

Unfortunately I have witnessed clear examples that this is not successful across a number of universities in the UK. I have seen specialist masters courses offered by a department that has no specialist expertise in that area. I have seen a module in an area that changes very quickly, where the module structure and content had not been updated in over 6 years and were completely out of date. I have seen a masters-level module where the assessment was to write a CV and skills assessment. I have seen modules where undergraduate and postgraduate students are taught the same content. I have seen modules that have received the same QA feedback on the content repeatedly, but where the module content has never been changed in response. Only a few examples, but these are really not scenarios that should be allowed to happen with a QA process in place. This is across a range of universities and QA process variations, thus clearly it is not an issue in the individual processes.

However, the problem is worse, as not only do the QA processes fail to stop the worst failings, they also actively inhibit good teaching. I here define good teaching as innovative, engaging students, adapting to the students’ needs, adapting to changes in the field. I will now show that the QA processes actively discourage or inhibit each of these characteristics.

The fundamental problem is that the QA processes are so slow and cumbersome, while the good teaching practices require fast adaptation. To adapt to students’ needs requires the ability to make changes during the running of the module. However, for the majority of QA processes the timescales required to make any changes are generally at least a few months and are unlikely to allow changes within the time when that module is run. This makes it near impossible to adapt to the students’ needs or changes in the field. To make matters worse even where the timescales make changes viable, the amount of paperwork required for even minor changes further discourages making changes to and adapting teaching content. Considering academics generally high workloads, this is not conductive to ensuring module content and structure are kept up to date.

Similarly, to develop innovative and engaging teaching requires breaking the mold. However, the QA processes, because they are applied to all disciplines, are by necessity very strict and do not allow for the flexibility needed for innovative and engaging teaching. In theory the QA processes could be adapted to support innovative teaching, but generally the way the QA processes are applied is in a cookie-cutter, sausage factory style. I am not entirely sure what the reason behind that is, but potentially it is due to the QA processes being led by non-subject experts, which leads to a focus on procedure rather than innovation.

As a result of these processes the academic is now faced with the choice to either structure their teaching to fit into the QA boxes, regardless of how appropriate the structure is, or to lie in the QA processes, which is a waste of time, but then be able to deliver quality teaching. Considering the first of those two approaches is less time-consuming and lower risk to the academic and that academics are very good at optimising their time, being forced into the QA processes actively lowers the the level of innovation, engagement, and adaptability of teaching, exactly the opposite of what it should be achieving.

Replies @hallicek
